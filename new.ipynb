{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597009355278",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from os import getcwd\n",
    "from os import listdir\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import imutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "YES_SOURCE_DIR = \"facemask-dataset/data/with_mask/\"\n",
    "TRAINING_YES_DIR = \"facemask-dataset/train/with_mask/\"\n",
    "TESTING_YES_DIR = \"facemask-dataset/test/with_mask/\"\n",
    "NO_SOURCE_DIR = \"facemask-dataset/data/without_mask/\"\n",
    "TRAINING_NO_DIR = \"facemask-dataset/train/without_mask/\"\n",
    "TESTING_NO_DIR = \"facemask-dataset/test/without_mask/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    dataset = []\n",
    "    \n",
    "    for unitData in os.listdir(SOURCE):\n",
    "        data = SOURCE + unitData\n",
    "        if(os.path.getsize(data) > 0):\n",
    "            dataset.append(unitData)\n",
    "        else:\n",
    "            print('Skipped ' + unitData)\n",
    "            print('Invalid file i.e zero size')\n",
    "    \n",
    "    train_set_length = int(len(dataset) * SPLIT_SIZE)\n",
    "    test_set_length = int(len(dataset) - train_set_length)\n",
    "    shuffled_set = random.sample(dataset, len(dataset))\n",
    "    train_set = dataset[0:train_set_length]\n",
    "    test_set = dataset[-test_set_length:]\n",
    "       \n",
    "    for unitData in train_set:\n",
    "        temp_train_set = SOURCE + unitData\n",
    "        final_train_set = TRAINING + unitData\n",
    "        copyfile(temp_train_set, final_train_set)\n",
    "    \n",
    "    for unitData in test_set:\n",
    "        temp_test_set = SOURCE + unitData\n",
    "        final_test_set = TESTING + unitData\n",
    "        copyfile(temp_test_set, final_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(TRAINING_YES_DIR, TESTING_YES_DIR, TRAINING_NO_DIR, TESTING_NO_DIR, i):\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "    model.save_weights('model.h5')\n",
    "    TRAINING_DIR = \"facemask-dataset/train\"\n",
    "    train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n",
    "                                                    batch_size=10, \n",
    "                                                    target_size=(150, 150))\n",
    "    VALIDATION_DIR = \"facemask-dataset/test\"\n",
    "    validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n",
    "                                                         batch_size=10, \n",
    "                                                         target_size=(150, 150))\n",
    "    mc = ModelCheckpoint('model-'+ str(i) + '-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "\n",
    "    history = model.fit_generator(train_generator,\n",
    "                              epochs = 50,\n",
    "                              validation_data = validation_generator,\n",
    "                              callbacks = [es, mc])\n",
    "\n",
    "    test_acc = model.evaluate(validation_generator, verbose = 0)\n",
    "\n",
    "    model.load_weights('model.h5')\n",
    "    return model, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=============================] - 65s 693ms/step - loss: 0.3541 - acc: 0.8454 - val_loss: 0.2686 - val_acc: 0.8941\nEpoch 32/50\n94/94 [==============================] - 66s 700ms/step - loss: 0.3520 - acc: 0.8561 - val_loss: 0.3047 - val_acc: 0.8941\nEpoch 33/50\n94/94 [==============================] - 67s 710ms/step - loss: 0.3679 - acc: 0.8561 - val_loss: 0.4072 - val_acc: 0.8644\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\n******************************************************************************\n>0.864\n##############################################################################\nFound 938 images belonging to 2 classes.\nFound 236 images belonging to 2 classes.\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 94 steps, validate for 24 steps\nEpoch 1/50\n93/94 [============================>.] - ETA: 0s - loss: 0.7328 - acc: 0.6185INFO:tensorflow:Assets written to: model-2-001.model\\assets\n94/94 [==============================] - 75s 799ms/step - loss: 0.7313 - acc: 0.6194 - val_loss: 0.5640 - val_acc: 0.7966\nEpoch 2/50\n94/94 [==============================] - 56s 594ms/step - loss: 0.5487 - acc: 0.7580 - val_loss: 0.5919 - val_acc: 0.7034\nEpoch 3/50\n93/94 [============================>.] - ETA: 0s - loss: 0.5259 - acc: 0.7586INFO:tensorflow:Assets written to: model-2-003.model\\assets\n94/94 [==============================] - 57s 607ms/step - loss: 0.5234 - acc: 0.7601 - val_loss: 0.4207 - val_acc: 0.7881\nEpoch 4/50\n94/94 [==============================] - 60s 636ms/step - loss: 0.4836 - acc: 0.7910 - val_loss: 0.4770 - val_acc: 0.7669\nEpoch 5/50\n94/94 [==============================] - 56s 592ms/step - loss: 0.5028 - acc: 0.7655 - val_loss: 0.5794 - val_acc: 0.7119\nEpoch 6/50\n94/94 [==============================] - 56s 596ms/step - loss: 0.5256 - acc: 0.7527 - val_loss: 0.4591 - val_acc: 0.7839\nEpoch 7/50\n93/94 [============================>.] - ETA: 0s - loss: 0.4518 - acc: 0.8114INFO:tensorflow:Assets written to: model-2-007.model\\assets\n94/94 [==============================] - 57s 604ms/step - loss: 0.4501 - acc: 0.8124 - val_loss: 0.3795 - val_acc: 0.8602\nEpoch 8/50\n93/94 [============================>.] - ETA: 0s - loss: 0.4183 - acc: 0.8258INFO:tensorflow:Assets written to: model-2-008.model\\assets\n94/94 [==============================] - 58s 612ms/step - loss: 0.4158 - acc: 0.8273 - val_loss: 0.3478 - val_acc: 0.8602\nEpoch 9/50\n94/94 [==============================] - 60s 643ms/step - loss: 0.4457 - acc: 0.7964 - val_loss: 0.4126 - val_acc: 0.8178\nEpoch 10/50\n93/94 [============================>.] - ETA: 0s - loss: 0.4557 - acc: 0.8147INFO:tensorflow:Assets written to: model-2-010.model\\assets\n94/94 [==============================] - 63s 668ms/step - loss: 0.4561 - acc: 0.8145 - val_loss: 0.3000 - val_acc: 0.8771\nEpoch 11/50\n94/94 [==============================] - 59s 626ms/step - loss: 0.4467 - acc: 0.8081 - val_loss: 0.3349 - val_acc: 0.8602\nEpoch 12/50\n94/94 [==============================] - 60s 643ms/step - loss: 0.4094 - acc: 0.8134 - val_loss: 0.3223 - val_acc: 0.8814\nEpoch 13/50\n94/94 [==============================] - 60s 637ms/step - loss: 0.4015 - acc: 0.8188 - val_loss: 0.3348 - val_acc: 0.8686\nEpoch 14/50\n94/94 [==============================] - 60s 637ms/step - loss: 0.4148 - acc: 0.8209 - val_loss: 0.3238 - val_acc: 0.8475\nEpoch 15/50\n94/94 [==============================] - 60s 635ms/step - loss: 0.4069 - acc: 0.8209 - val_loss: 0.6373 - val_acc: 0.7669\nEpoch 16/50\n94/94 [==============================] - 60s 640ms/step - loss: 0.4641 - acc: 0.7974 - val_loss: 0.4029 - val_acc: 0.8602\nEpoch 17/50\n93/94 [============================>.] - ETA: 0s - loss: 0.4201 - acc: 0.8190INFO:tensorflow:Assets written to: model-2-017.model\\assets\n94/94 [==============================] - 61s 653ms/step - loss: 0.4183 - acc: 0.8198 - val_loss: 0.2905 - val_acc: 0.8729\nEpoch 18/50\n94/94 [==============================] - 60s 642ms/step - loss: 0.4187 - acc: 0.8230 - val_loss: 0.3317 - val_acc: 0.8686\nEpoch 19/50\n93/94 [============================>.] - ETA: 0s - loss: 0.4063 - acc: 0.8136INFO:tensorflow:Assets written to: model-2-019.model\\assets\n94/94 [==============================] - 63s 675ms/step - loss: 0.4047 - acc: 0.8145 - val_loss: 0.2733 - val_acc: 0.9025\nEpoch 20/50\n94/94 [==============================] - 63s 670ms/step - loss: 0.3845 - acc: 0.8433 - val_loss: 0.3126 - val_acc: 0.8898\nEpoch 21/50\n94/94 [==============================] - 60s 642ms/step - loss: 0.3879 - acc: 0.8390 - val_loss: 0.3963 - val_acc: 0.8644\nEpoch 22/50\n94/94 [==============================] - 62s 664ms/step - loss: 0.3811 - acc: 0.8358 - val_loss: 0.3158 - val_acc: 0.8686\nEpoch 23/50\n94/94 [==============================] - 62s 657ms/step - loss: 0.4060 - acc: 0.8156 - val_loss: 0.3137 - val_acc: 0.8856\nEpoch 24/50\n93/94 [============================>.] - ETA: 0s - loss: 0.3619 - acc: 0.8330INFO:tensorflow:Assets written to: model-2-024.model\\assets\n94/94 [==============================] - 62s 657ms/step - loss: 0.3645 - acc: 0.8326 - val_loss: 0.2645 - val_acc: 0.9110\nEpoch 25/50\n94/94 [==============================] - 61s 649ms/step - loss: 0.3632 - acc: 0.8443 - val_loss: 0.3388 - val_acc: 0.8771\nEpoch 26/50\n94/94 [==============================] - 61s 651ms/step - loss: 0.3832 - acc: 0.8326 - val_loss: 0.2953 - val_acc: 0.8814\nEpoch 27/50\n94/94 [==============================] - 61s 651ms/step - loss: 0.3587 - acc: 0.8465 - val_loss: 0.3266 - val_acc: 0.8856\nEpoch 28/50\n94/94 [==============================] - 61s 645ms/step - loss: 0.3881 - acc: 0.8358 - val_loss: 0.2650 - val_acc: 0.8983\nEpoch 29/50\n94/94 [==============================] - 63s 666ms/step - loss: 0.3624 - acc: 0.8529 - val_loss: 0.2981 - val_acc: 0.8898\nEpoch 30/50\n94/94 [==============================] - 62s 658ms/step - loss: 0.3819 - acc: 0.8550 - val_loss: 0.3470 - val_acc: 0.8814\nEpoch 31/50\n94/94 [==============================] - 61s 651ms/step - loss: 0.3642 - acc: 0.8412 - val_loss: 0.3156 - val_acc: 0.8771\nEpoch 32/50\n94/94 [==============================] - 63s 673ms/step - loss: 0.3588 - acc: 0.8401 - val_loss: 0.2810 - val_acc: 0.9025\nEpoch 33/50\n94/94 [==============================] - 61s 651ms/step - loss: 0.3585 - acc: 0.8486 - val_loss: 0.3168 - val_acc: 0.8856\nEpoch 34/50\n94/94 [==============================] - 61s 652ms/step - loss: 0.3408 - acc: 0.8593 - val_loss: 0.3101 - val_acc: 0.8898\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\n******************************************************************************\n>0.890\n##############################################################################\nFound 938 images belonging to 2 classes.\nFound 236 images belonging to 2 classes.\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 94 steps, validate for 24 steps\nEpoch 1/50\n93/94 [============================>.] - ETA: 0s - loss: 0.7311 - acc: 0.6433INFO:tensorflow:Assets written to: model-3-001.model\\assets\n94/94 [==============================] - 69s 736ms/step - loss: 0.7303 - acc: 0.6429 - val_loss: 0.5275 - val_acc: 0.7839\nEpoch 2/50\n93/94 [============================>.] - ETA: 0s - loss: 0.5677 - acc: 0.7468INFO:tensorflow:Assets written to: model-3-002.model\\assets\n94/94 [==============================] - 62s 657ms/step - loss: 0.5684 - acc: 0.7473 - val_loss: 0.4275 - val_acc: 0.8602\nEpoch 3/50\n94/94 [==============================] - 62s 656ms/step - loss: 0.5024 - acc: 0.7708 - val_loss: 0.5401 - val_acc: 0.7754\nEpoch 4/50\n93/94 [============================>.] - ETA: 0s - loss: 0.4687 - acc: 0.7953INFO:tensorflow:Assets written to: model-3-004.model\\assets\n94/94 [==============================] - 64s 686ms/step - loss: 0.4683 - acc: 0.7953 - val_loss: 0.3704 - val_acc: 0.8475\nEpoch 5/50\n94/94 [==============================] - 68s 718ms/step - loss: 0.4879 - acc: 0.7751 - val_loss: 0.4062 - val_acc: 0.8051\nEpoch 6/50\n93/94 [============================>.] - ETA: 0s - loss: 0.4998 - acc: 0.7608INFO:tensorflow:Assets written to: model-3-006.model\\assets\n94/94 [==============================] - 62s 662ms/step - loss: 0.5045 - acc: 0.7591 - val_loss: 0.3501 - val_acc: 0.8898\nEpoch 7/50\n94/94 [==============================] - 63s 673ms/step - loss: 0.4847 - acc: 0.7868 - val_loss: 0.3826 - val_acc: 0.8517\nEpoch 8/50\n93/94 [============================>.] - ETA: 0s - loss: 0.4140 - acc: 0.8244INFO:tensorflow:Assets written to: model-3-008.model\\assets\n94/94 [==============================] - 62s 661ms/step - loss: 0.4135 - acc: 0.8241 - val_loss: 0.3265 - val_acc: 0.8771\nEpoch 9/50\n93/94 [============================>.] - ETA: 0s - loss: 0.4516 - acc: 0.7953INFO:tensorflow:Assets written to: model-3-009.model\\assets\n94/94 [==============================] - 63s 673ms/step - loss: 0.4520 - acc: 0.7953 - val_loss: 0.3016 - val_acc: 0.8771\nEpoch 10/50\n94/94 [==============================] - 61s 652ms/step - loss: 0.4315 - acc: 0.8230 - val_loss: 0.3177 - val_acc: 0.8644\nEpoch 11/50\n93/94 [============================>.] - ETA: 0s - loss: 0.4313 - acc: 0.8179INFO:tensorflow:Assets written to: model-3-011.model\\assets\n94/94 [==============================] - 62s 663ms/step - loss: 0.4285 - acc: 0.8198 - val_loss: 0.2831 - val_acc: 0.8898\nEpoch 12/50\n94/94 [==============================] - 61s 654ms/step - loss: 0.3967 - acc: 0.8284 - val_loss: 0.3712 - val_acc: 0.8517\nEpoch 13/50\n94/94 [==============================] - 62s 655ms/step - loss: 0.4132 - acc: 0.8326 - val_loss: 0.3026 - val_acc: 0.8941\nEpoch 14/50\n94/94 [==============================] - 63s 675ms/step - loss: 0.4164 - acc: 0.8124 - val_loss: 0.3610 - val_acc: 0.8686\nEpoch 15/50\n94/94 [==============================] - 61s 653ms/step - loss: 0.3944 - acc: 0.8348 - val_loss: 0.3268 - val_acc: 0.8941\nEpoch 16/50\n94/94 [==============================] - 61s 649ms/step - loss: 0.4219 - acc: 0.8081 - val_loss: 0.3393 - val_acc: 0.8517\nEpoch 17/50\n94/94 [==============================] - 63s 668ms/step - loss: 0.3822 - acc: 0.8305 - val_loss: 0.4208 - val_acc: 0.8305\nEpoch 18/50\n94/94 [==============================] - 61s 652ms/step - loss: 0.3891 - acc: 0.8422 - val_loss: 0.3136 - val_acc: 0.8729\nEpoch 19/50\n94/94 [==============================] - 61s 645ms/step - loss: 0.3900 - acc: 0.8422 - val_loss: 0.2991 - val_acc: 0.8941\nEpoch 20/50\n93/94 [============================>.] - ETA: 0s - loss: 0.3688 - acc: 0.8416INFO:tensorflow:Assets written to: model-3-020.model\\assets\n94/94 [==============================] - 62s 660ms/step - loss: 0.3714 - acc: 0.8422 - val_loss: 0.2684 - val_acc: 0.9025\nEpoch 21/50\n94/94 [==============================] - 61s 648ms/step - loss: 0.3913 - acc: 0.8273 - val_loss: 0.2789 - val_acc: 0.8983\nEpoch 22/50\n93/94 [============================>.] - ETA: 0s - loss: 0.4014 - acc: 0.8330INFO:tensorflow:Assets written to: model-3-022.model\\assets\n94/94 [==============================] - 62s 658ms/step - loss: 0.4073 - acc: 0.8316 - val_loss: 0.2552 - val_acc: 0.9025\nEpoch 23/50\n93/94 [============================>.] - ETA: 0s - loss: 0.3695 - acc: 0.8373INFO:tensorflow:Assets written to: model-3-023.model\\assets\n94/94 [==============================] - 62s 661ms/step - loss: 0.3660 - acc: 0.8390 - val_loss: 0.2452 - val_acc: 0.9110\nEpoch 24/50\n94/94 [==============================] - 62s 661ms/step - loss: 0.3724 - acc: 0.8454 - val_loss: 0.2502 - val_acc: 0.9195\nEpoch 25/50\n94/94 [==============================] - 61s 650ms/step - loss: 0.3814 - acc: 0.8422 - val_loss: 0.2792 - val_acc: 0.9068\nEpoch 26/50\n94/94 [==============================] - 61s 645ms/step - loss: 0.3477 - acc: 0.8497 - val_loss: 0.3382 - val_acc: 0.8856\nEpoch 27/50\n94/94 [==============================] - 63s 673ms/step - loss: 0.4231 - acc: 0.8209 - val_loss: 0.2620 - val_acc: 0.9153\nEpoch 28/50\n94/94 [==============================] - 64s 686ms/step - loss: 0.3889 - acc: 0.8294 - val_loss: 0.2920 - val_acc: 0.8856\nEpoch 29/50\n94/94 [==============================] - 61s 653ms/step - loss: 0.3641 - acc: 0.8529 - val_loss: 0.2928 - val_acc: 0.8983\nEpoch 30/50\n94/94 [==============================] - 60s 641ms/step - loss: 0.3620 - acc: 0.8390 - val_loss: 0.2831 - val_acc: 0.9237\nEpoch 31/50\n94/94 [==============================] - 60s 643ms/step - loss: 0.3860 - acc: 0.8443 - val_loss: 0.2562 - val_acc: 0.9025\nEpoch 32/50\n93/94 [============================>.] - ETA: 0s - loss: 0.3664 - acc: 0.8502INFO:tensorflow:Assets written to: model-3-032.model\\assets\n94/94 [==============================] - 61s 651ms/step - loss: 0.3635 - acc: 0.8518 - val_loss: 0.2418 - val_acc: 0.9280\nEpoch 33/50\n94/94 [==============================] - 63s 672ms/step - loss: 0.3592 - acc: 0.8475 - val_loss: 0.3016 - val_acc: 0.8729\nEpoch 34/50\n94/94 [==============================] - 63s 671ms/step - loss: 0.3692 - acc: 0.8369 - val_loss: 0.2792 - val_acc: 0.9068\nEpoch 35/50\n94/94 [==============================] - 60s 642ms/step - loss: 0.3716 - acc: 0.8412 - val_loss: 0.2433 - val_acc: 0.9322\nEpoch 36/50\n94/94 [==============================] - 62s 658ms/step - loss: 0.3527 - acc: 0.8529 - val_loss: 0.2654 - val_acc: 0.9068\nEpoch 37/50\n94/94 [==============================] - 61s 649ms/step - loss: 0.3517 - acc: 0.8497 - val_loss: 0.2824 - val_acc: 0.9025\nEpoch 38/50\n94/94 [==============================] - 60s 641ms/step - loss: 0.3607 - acc: 0.8486 - val_loss: 0.2762 - val_acc: 0.9068\nEpoch 39/50\n94/94 [==============================] - 60s 644ms/step - loss: 0.3441 - acc: 0.8518 - val_loss: 0.2680 - val_acc: 0.8983\nEpoch 40/50\n94/94 [==============================] - 60s 642ms/step - loss: 0.3481 - acc: 0.8603 - val_loss: 0.2513 - val_acc: 0.9195\nEpoch 41/50\n93/94 [============================>.] - ETA: 0s - loss: 0.3482 - acc: 0.8416INFO:tensorflow:Assets written to: model-3-041.model\\assets\n94/94 [==============================] - 61s 649ms/step - loss: 0.3508 - acc: 0.8401 - val_loss: 0.2413 - val_acc: 0.9322\nEpoch 42/50\n94/94 [==============================] - 61s 645ms/step - loss: 0.4083 - acc: 0.8337 - val_loss: 0.2868 - val_acc: 0.9068\nEpoch 43/50\n94/94 [==============================] - 62s 658ms/step - loss: 0.3546 - acc: 0.8539 - val_loss: 0.2771 - val_acc: 0.9110\nEpoch 44/50\n94/94 [==============================] - 61s 654ms/step - loss: 0.3459 - acc: 0.8571 - val_loss: 0.2595 - val_acc: 0.8983\nEpoch 45/50\n94/94 [==============================] - 60s 641ms/step - loss: 0.3616 - acc: 0.8518 - val_loss: 0.2602 - val_acc: 0.9068\nEpoch 46/50\n94/94 [==============================] - 62s 662ms/step - loss: 0.3242 - acc: 0.8699 - val_loss: 0.3014 - val_acc: 0.8814\nEpoch 47/50\n94/94 [==============================] - 60s 643ms/step - loss: 0.3358 - acc: 0.8603 - val_loss: 0.3059 - val_acc: 0.8898\nEpoch 48/50\n94/94 [==============================] - 60s 640ms/step - loss: 0.3474 - acc: 0.8561 - val_loss: 0.2467 - val_acc: 0.9110\nEpoch 49/50\n94/94 [==============================] - 60s 639ms/step - loss: 0.3599 - acc: 0.8539 - val_loss: 0.2944 - val_acc: 0.9025\nEpoch 50/50\n94/94 [==============================] - 61s 645ms/step - loss: 0.3510 - acc: 0.8422 - val_loss: 0.3092 - val_acc: 0.8856\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\n******************************************************************************\n>0.886\n##############################################################################\nFound 938 images belonging to 2 classes.\nFound 236 images belonging to 2 classes.\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 94 steps, validate for 24 steps\nEpoch 1/50\n93/94 [============================>.] - ETA: 0s - loss: 0.6668 - acc: 0.6659INFO:tensorflow:Assets written to: model-4-001.model\\assets\n94/94 [==============================] - 69s 739ms/step - loss: 0.6616 - acc: 0.6695 - val_loss: 0.3256 - val_acc: 0.8686\nEpoch 2/50\n94/94 [==============================] - 63s 667ms/step - loss: 0.5054 - acc: 0.7559 - val_loss: 0.3792 - val_acc: 0.8305\nEpoch 3/50\n94/94 [==============================] - 64s 678ms/step - loss: 0.4511 - acc: 0.7942 - val_loss: 0.3642 - val_acc: 0.8432\nEpoch 4/50\n94/94 [==============================] - 61s 652ms/step - loss: 0.4536 - acc: 0.7932 - val_loss: 0.3292 - val_acc: 0.8729\nEpoch 5/50\n93/94 [============================>.] - ETA: 0s - loss: 0.3912 - acc: 0.8244INFO:tensorflow:Assets written to: model-4-005.model\\assets\n94/94 [==============================] - 65s 690ms/step - loss: 0.3904 - acc: 0.8252 - val_loss: 0.2801 - val_acc: 0.8729\nEpoch 6/50\n94/94 [==============================] - 64s 679ms/step - loss: 0.3809 - acc: 0.8401 - val_loss: 0.2940 - val_acc: 0.8729\nEpoch 7/50\n93/94 [============================>.] - ETA: 0s - loss: 0.3970 - acc: 0.8147INFO:tensorflow:Assets written to: model-4-007.model\\assets\n94/94 [==============================] - 62s 664ms/step - loss: 0.3949 - acc: 0.8156 - val_loss: 0.2449 - val_acc: 0.8941\nEpoch 8/50\n94/94 [==============================] - 61s 650ms/step - loss: 0.3918 - acc: 0.8390 - val_loss: 0.3208 - val_acc: 0.8475\nEpoch 9/50\n94/94 [==============================] - 61s 653ms/step - loss: 0.3902 - acc: 0.8230 - val_loss: 0.2785 - val_acc: 0.8983\nEpoch 10/50\n94/94 [==============================] - 61s 646ms/step - loss: 0.3917 - acc: 0.8134 - val_loss: 0.3080 - val_acc: 0.8771\nEpoch 11/50\n94/94 [==============================] - 61s 648ms/step - loss: 0.3801 - acc: 0.8273 - val_loss: 0.3084 - val_acc: 0.8729\nEpoch 12/50\n94/94 [==============================] - 64s 679ms/step - loss: 0.3624 - acc: 0.8369 - val_loss: 0.2908 - val_acc: 0.8856\nEpoch 13/50\n94/94 [==============================] - 68s 723ms/step - loss: 0.3714 - acc: 0.8252 - val_loss: 0.3311 - val_acc: 0.8814\nEpoch 14/50\n93/94 [============================>.] - ETA: 0s - loss: 0.3757 - acc: 0.8384INFO:tensorflow:Assets written to: model-4-014.model\\assets\n94/94 [==============================] - 68s 728ms/step - loss: 0.3728 - acc: 0.8401 - val_loss: 0.2278 - val_acc: 0.9110\nEpoch 15/50\n94/94 [==============================] - 67s 709ms/step - loss: 0.4021 - acc: 0.8241 - val_loss: 0.2955 - val_acc: 0.8729\nEpoch 16/50\n94/94 [==============================] - 66s 701ms/step - loss: 0.3525 - acc: 0.8475 - val_loss: 0.3713 - val_acc: 0.8263\nEpoch 17/50\n94/94 [==============================] - 66s 705ms/step - loss: 0.3774 - acc: 0.8326 - val_loss: 0.2511 - val_acc: 0.9025\nEpoch 18/50\n94/94 [==============================] - 67s 709ms/step - loss: 0.3510 - acc: 0.8507 - val_loss: 0.2703 - val_acc: 0.8771\nEpoch 19/50\n94/94 [==============================] - 67s 712ms/step - loss: 0.3453 - acc: 0.8497 - val_loss: 0.2878 - val_acc: 0.8771\nEpoch 20/50\n94/94 [==============================] - 67s 713ms/step - loss: 0.3368 - acc: 0.8699 - val_loss: 0.2611 - val_acc: 0.9068\nEpoch 21/50\n94/94 [==============================] - 67s 711ms/step - loss: 0.3516 - acc: 0.8475 - val_loss: 0.2660 - val_acc: 0.8941\nEpoch 22/50\n94/94 [==============================] - 66s 704ms/step - loss: 0.3411 - acc: 0.8571 - val_loss: 0.2972 - val_acc: 0.8941\nEpoch 23/50\n94/94 [==============================] - 60s 636ms/step - loss: 0.3621 - acc: 0.8369 - val_loss: 0.2841 - val_acc: 0.9025\nEpoch 24/50\n94/94 [==============================] - 65s 687ms/step - loss: 0.3389 - acc: 0.8465 - val_loss: 0.2536 - val_acc: 0.9153\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\n******************************************************************************\n>0.915\n##############################################################################\nEstimated Accuracy 0.886 (0.017)\n"
    }
   ],
   "source": [
    "n_folds = 5\n",
    "cv_scores, model_history = list(), list()\n",
    "for i in range(n_folds):\n",
    "    # split data\n",
    "    split_size = 0.8\n",
    "    split_data(YES_SOURCE_DIR, TRAINING_YES_DIR, TESTING_YES_DIR, split_size)\n",
    "    split_data(NO_SOURCE_DIR, TRAINING_NO_DIR, TESTING_NO_DIR, split_size)\n",
    "    # evaluate model\n",
    "    model, test_acc = evaluate_model(TRAINING_YES_DIR, TESTING_YES_DIR, TRAINING_NO_DIR, TESTING_NO_DIR, i)\n",
    "    print(\"******************************************************************************\")\n",
    "    print('>%.3f' % test_acc[1])\n",
    "    print(\"##############################################################################\")\n",
    "    cv_scores.append(test_acc[1])\n",
    "    model_history.append(model)\n",
    "    \n",
    "print('Estimated Accuracy %.3f (%.3f)' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.87711865, 0.86440676, 0.8898305, 0.88559324, 0.91525424]\n"
    }
   ],
   "source": [
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}