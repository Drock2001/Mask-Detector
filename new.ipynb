{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597758152828",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from os import getcwd\n",
    "from os import listdir\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "import imutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as mpimg\n",
    "import kerastuner\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import time\n",
    "import pandas as pd\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.client.session.Session at 0x20b868e3cc0>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "gpu_options= tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction = 0.5)\n",
    "tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options= gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "YES_SOURCE_DIR = \"facemask-dataset/data/with_mask/\"\n",
    "TRAINING_YES_DIR = \"facemask-dataset/train/with_mask/\"\n",
    "TESTING_YES_DIR = \"facemask-dataset/test/with_mask/\"\n",
    "NO_SOURCE_DIR = \"facemask-dataset/data/without_mask/\"\n",
    "TRAINING_NO_DIR = \"facemask-dataset/train/without_mask/\"\n",
    "TESTING_NO_DIR = \"facemask-dataset/test/without_mask/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_dataset(SOURCE):\n",
    "    dataset = []\n",
    "    for unitData in os.listdir(SOURCE):\n",
    "        data = SOURCE + unitData\n",
    "        if(os.path.getsize(data) > 0):\n",
    "            dataset.append(unitData)\n",
    "        else:\n",
    "            print('Skipped ' + unitData)\n",
    "            print('Invalid file i.e zero size')\n",
    "    \n",
    "    shuffled_set = random.sample(dataset, len(dataset))\n",
    "    return shuffled_set\n",
    "\n",
    "\n",
    "def split_data(shuffled_set, SOURCE, TRAINING, TESTING, SPLIT_SIZE, k, n_folds):\n",
    "    l = len(shuffled_set) / n_folds\n",
    "\n",
    "    test_set = shuffled_set[int((k-1)*l) : int(k*l)]\n",
    "    for unitData in test_set:\n",
    "        temp_test_set = SOURCE + unitData\n",
    "        final_test_set = TESTING + unitData\n",
    "        copyfile(temp_test_set, final_test_set)\n",
    "\n",
    "    train_set = shuffled_set[0:int((k-1)*l)] + shuffled_set[int(k*l): len(shuffled_set)]\n",
    "    for unitData in train_set:\n",
    "        temp_train_set = SOURCE + unitData\n",
    "        final_train_set = TRAINING + unitData\n",
    "        copyfile(temp_train_set, final_train_set)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(176, kernel_size = 5, activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(192, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "     \n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(160, activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.7),\n",
    "    \n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, TRAINING_YES_DIR, TESTING_YES_DIR, TRAINING_NO_DIR, TESTING_NO_DIR, i):\n",
    "    name = \"lg-\" + str(i+1) + \"-\" + str(int(time.time()))\n",
    "    logdir = \"log/\" + name\n",
    "    tb = TensorBoard(log_dir = logdir, histogram_freq=1, write_images=True, update_freq='epoch', embeddings_freq=5)\n",
    "    TRAINING_DIR = \"facemask-dataset/train-\" + str(i+1)\n",
    "    train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n",
    "                                                    batch_size=32, \n",
    "                                                    target_size=(150, 150))\n",
    "    VALIDATION_DIR = \"facemask-dataset/test-\" + str(i+1)\n",
    "    validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n",
    "                                                         batch_size=32, \n",
    "                                                         target_size=(150, 150))\n",
    "    model.load_weights('model.h5')\n",
    "    checkpoint_path = 'best_model-'+ str(i+1)\n",
    "    mc = ModelCheckpoint(checkpoint_path,monitor='val_loss',verbose=1,save_best_only=True,mode='min')\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(train_generator,\n",
    "                        epochs = 500,\n",
    "                        validation_data = validation_generator,\n",
    "                        callbacks = [es, mc, tb], verbose=1)\n",
    "    \n",
    "    model = load_model(checkpoint_path)\n",
    "    \n",
    "    test_acc = model.evaluate(validation_generator, verbose = 1)\n",
    "    '''\n",
    "    #plotting loss \n",
    "    loss_train = history.history['loss']\n",
    "    loss_val = history.history['val_loss']\n",
    "    epochs = range(1, len(history.history['loss']) + 1)\n",
    "    plt.plot(epochs, loss_train, 'g', label=\"training loss\")\n",
    "    plt.plot(epochs, loss_val, 'b', label=\"validation loss\")\n",
    "    plt.title(\"training and validation loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    #plotting accuracy\n",
    "    acc_train = history.history['accuracy']\n",
    "    acc_val = history.history['val_accuracy']\n",
    "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "    plt.plot(epochs, acc_train, 'g', label=\"training acc\")\n",
    "    plt.plot(epochs, acc_val, 'b', label=\"validation acc\")\n",
    "    plt.title(\"training and validation acc\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "    '''\n",
    "    model.save_weights('model.h5')\n",
    "    return model, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 2006 images belonging to 2 classes.\nFound 802 images belonging to 2 classes.\nEpoch 1/500\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5f128cba2ea0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# evaluate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAINING_YES_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTESTING_YES_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAINING_NO_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTESTING_NO_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"**********************************************************************************************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'>%.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-239298e277b3>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(model, TRAINING_YES_DIR, TESTING_YES_DIR, TRAINING_NO_DIR, TESTING_NO_DIR, i)\u001b[0m\n\u001b[0;32m     30\u001b[0m                         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                         \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                         callbacks = [es, mc, tb], verbose=1)\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "cv_scores, model_history = list(), list()\n",
    "YES_SOURCE_DIR = \"facemask-dataset/data/with_mask/\"\n",
    "NO_SOURCE_DIR = \"facemask-dataset/data/without_mask/\"\n",
    "#YES_SET = making_dataset(YES_SOURCE_DIR)\n",
    "#NO_SET = making_dataset(NO_SOURCE_DIR)\n",
    "mod = build_model()\n",
    "#mod.save_weights('model.h5')\n",
    "for i in range(n_folds):\n",
    "    \n",
    "    TRAINING_YES_DIR = \"facemask-dataset/train-\" + str(5) + \"/with_mask/\"\n",
    "    TESTING_YES_DIR = \"facemask-dataset/test-\" + str(5) + \"/with_mask/\"\n",
    "    \n",
    "    TRAINING_NO_DIR = \"facemask-dataset/train-\" + str(5) + \"/without_mask/\"\n",
    "    TESTING_NO_DIR = \"facemask-dataset/test-\" + str(i+1) + \"/without_mask/\"\n",
    "    # split data\n",
    "    \n",
    "    split_size = 0.8\n",
    "    split_data(YES_SET, YES_SOURCE_DIR, TRAINING_YES_DIR, TESTING_YES_DIR, split_size, 5, n_folds)\n",
    "    split_data(NO_SET ,NO_SOURCE_DIR, TRAINING_NO_DIR, TESTING_NO_DIR, split_size, 5, n_folds)\n",
    "    \n",
    "    # evaluate model\n",
    "    model, test_acc = evaluate_model(mod, TRAINING_YES_DIR, TESTING_YES_DIR, TRAINING_NO_DIR, TESTING_NO_DIR, i)\n",
    "    print(\"**********************************************************************************************\")\n",
    "    print('>%.3f' % test_acc[1])\n",
    "    print(\"##############################################################################################\")\n",
    "    cv_scores.append(test_acc[1])\n",
    "    model_history.append(model)\n",
    "    \n",
    "print('Estimated Accuracy: %.3f with standard deviaton: %.3f' % (np.mean(cv_scores), np.std(cv_scores)))\n",
    "print(\"##############################################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: best_model\\assets\n"
    }
   ],
   "source": [
    "max = cv_scores.index(np.max(cv_scores))\n",
    "checkpoint = 'best_model-'+ str(max+1)\n",
    "mod = load_model(checkpoint)\n",
    "mod.save('best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 306 images belonging to 2 classes.\n{'with_mask': 0, 'without_mask': 1}\n              precision    recall  f1-score   support\n\nwithout_mask       0.94      0.95      0.95       153\n        mask       0.95      0.94      0.95       153\n\n    accuracy                           0.95       306\n   macro avg       0.95      0.95      0.95       306\nweighted avg       0.95      0.95      0.95       306\n\n##############################################################################################\nBest accuracy: 0.9452736377716064\n"
    }
   ],
   "source": [
    "TEST_DIR = \"facemask-dataset/val\"\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(TEST_DIR, \n",
    "                                                         batch_size=306,\n",
    "                                                         class_mode=\"binary\",\n",
    "                                                         target_size=(150, 150))\n",
    "testx, testy = next(test_generator)\n",
    "print(test_generator.class_indices)\n",
    "predIdxs = mod.predict(testx, batch_size=306)\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "print(classification_report(testy, predIdxs,target_names=['without_mask', 'mask']))\n",
    "print(\"##############################################################################################\")\n",
    "print(\"Best accuracy: \" + str(cv_scores[max]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.9399999976158142, 0.927860677242279, 0.9449999928474426, 0.9452736377716064]\n"
    }
   ],
   "source": [
    "print(cv_scores)\n",
    "df = pd.DataFrame(cv_scores)\n",
    "df.to_csv('scores.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_dict={0:'without_mask', 1:'with_mask'}\n",
    "color_dict={0:(0,0,255),1:(0,255,0)}\n",
    "j = 0\n",
    "counter = 0\n",
    "size = 4\n",
    "webcam = cv2.VideoCapture(0) #Use camera 0\n",
    "#address = \"https://192.168.43.1:8080/video\"\n",
    "#webcam.open(address)\n",
    "checkpoint = 'best_model'\n",
    "model = load_model(checkpoint)\n",
    "# We load the xml file\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    fps = webcam.get(cv2.CAP_PROP_FPS)\n",
    "    (rval, im) = webcam.read()\n",
    "    im=cv2.flip(im,1,1) #Flip to act as a mirror\n",
    "    \n",
    "    # Resize the image to speed up detection\n",
    "    mini = cv2.resize(im, (im.shape[1] // size, im.shape[0] // size))\n",
    "\n",
    "    # detect MultiScale / faces \n",
    "    faces = classifier.detectMultiScale(mini)\n",
    "\n",
    "    # Draw rectangles around each face\n",
    "    for f in faces:\n",
    "        (x, y, w, h) = [v * size for v in f] #Scale the shapesize backup\n",
    "        #Save just the rectangle faces in SubRecFaces\n",
    "        face_img = im[y:y+h, x:x+w]\n",
    "        resized=cv2.resize(face_img,(150,150))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,150,150,3))\n",
    "        reshaped = np.vstack([reshaped])\n",
    "        result=model.predict(reshaped)\n",
    "        #print(result)\n",
    "        \n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "\n",
    "        if label == 1:\n",
    "            j+=1\n",
    "        elif label == 0:\n",
    "            j=0\n",
    "            freq = 2500\n",
    "            dur = 100\n",
    "            winsound.Beep(freq, dur)\n",
    "\n",
    "        if j>=30:\n",
    "            j=0\n",
    "            counter+=1\n",
    "\n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(im,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        cv2.putText(im, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "    # Show the image\n",
    "    f = \"FPS: \"+ str(fps)\n",
    "    cv2.putText(im, f, (30, 30),cv2.FONT_HERSHEY_SIMPLEX,1,(225,255,225),2)\n",
    "    textsize = cv2.getTextSize(str(counter), cv2.FONT_HERSHEY_SIMPLEX, 6, 10)[0]\n",
    "    xx = int((im.shape[1] - textsize[0]) / 2)\n",
    "    yy = int((im.shape[0] - textsize[1]) / 2)\n",
    "    cv2.putText(im, str(counter), (xx, yy + 100),cv2.FONT_HERSHEY_SIMPLEX,6,(0,255,0),10)\n",
    "    cv2.imshow('LIVE', im)\n",
    "    # if q key is press then break out of the loop \n",
    "    if cv2.waitKey(10) & 0xFF == ord(\"q\"): #The q key\n",
    "        break\n",
    "# Stop video\n",
    "webcam.release()\n",
    "\n",
    "# Close all started windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}