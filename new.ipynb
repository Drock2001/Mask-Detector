{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597009355278",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from os import getcwd\n",
    "from os import listdir\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import imutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "YES_SOURCE_DIR = \"facemask-dataset/data/with_mask/\"\n",
    "TRAINING_YES_DIR = \"facemask-dataset/train-\" + str(i+1) + \"/with_mask/\"\n",
    "TESTING_YES_DIR = \"facemask-dataset/test-\" + str(i+1) + \"/with_mask/\"\n",
    "NO_SOURCE_DIR = \"facemask-dataset/data/without_mask/\"\n",
    "TRAINING_NO_DIR = \"facemask-dataset/train-\" + str(i+1) + \"/without_mask/\"\n",
    "TESTING_NO_DIR = \"facemask-dataset/test-\" + str(i+1) + \"/without_mask/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    dataset = []\n",
    "    \n",
    "    for unitData in os.listdir(SOURCE):\n",
    "        data = SOURCE + unitData\n",
    "        if(os.path.getsize(data) > 0):\n",
    "            dataset.append(unitData)\n",
    "        else:\n",
    "            print('Skipped ' + unitData)\n",
    "            print('Invalid file i.e zero size')\n",
    "    \n",
    "    train_set_length = int(len(dataset) * SPLIT_SIZE)\n",
    "    test_set_length = int(len(dataset) - train_set_length)\n",
    "    shuffled_set = random.sample(dataset, len(dataset))\n",
    "    train_set = dataset[0:train_set_length]\n",
    "    test_set = dataset[-test_set_length:]\n",
    "       \n",
    "    for unitData in train_set:\n",
    "        temp_train_set = SOURCE + unitData\n",
    "        final_train_set = TRAINING + unitData\n",
    "        copyfile(temp_train_set, final_train_set)\n",
    "    \n",
    "    for unitData in test_set:\n",
    "        temp_test_set = SOURCE + unitData\n",
    "        final_test_set = TESTING + unitData\n",
    "        copyfile(temp_test_set, final_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(TRAINING_YES_DIR, TESTING_YES_DIR, TRAINING_NO_DIR, TESTING_NO_DIR, i):\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "    model.save_weights('model.h5')\n",
    "    TRAINING_DIR = \"facemask-dataset/train-\" + str(i+1)\n",
    "    train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n",
    "                                                    batch_size=10, \n",
    "                                                    target_size=(150, 150))\n",
    "    VALIDATION_DIR = \"facemask-dataset/test-\" + str(i+1)\n",
    "    validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n",
    "                                                         batch_size=10, \n",
    "                                                         target_size=(150, 150))\n",
    "    \n",
    "    checkpoint_path = 'best_model-'+ str(i+1)\n",
    "    mc = ModelCheckpoint(checkpoint_path,monitor='val_loss',verbose=0,save_best_only=True,mode='min')\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "\n",
    "    history = model.fit_generator(train_generator,\n",
    "                              epochs = 2,\n",
    "                              validation_data = validation_generator,\n",
    "                              callbacks = [es, mc])\n",
    "\n",
    "    model = load_model(checkpoint_path)\n",
    "\n",
    "    test_acc = model.evaluate(validation_generator, verbose = 0)\n",
    "\n",
    "    model.load_weights('model.h5')\n",
    "    return model, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "cv_scores, model_history = list(), list()\n",
    "for i in range(n_folds):\n",
    "    YES_SOURCE_DIR = \"facemask-dataset/data/with_mask/\"\n",
    "    TRAINING_YES_DIR = \"facemask-dataset/train-\" + str(i+1) + \"/with_mask/\"\n",
    "    TESTING_YES_DIR = \"facemask-dataset/test-\" + str(i+1) + \"/with_mask/\"\n",
    "    NO_SOURCE_DIR = \"facemask-dataset/data/without_mask/\"\n",
    "    TRAINING_NO_DIR = \"facemask-dataset/train-\" + str(i+1) + \"/without_mask/\"\n",
    "    TESTING_NO_DIR = \"facemask-dataset/test-\" + str(i+1) + \"/without_mask/\"\n",
    "    # split data\n",
    "    split_size = 0.8\n",
    "    split_data(YES_SOURCE_DIR, TRAINING_YES_DIR, TESTING_YES_DIR, split_size)\n",
    "    split_data(NO_SOURCE_DIR, TRAINING_NO_DIR, TESTING_NO_DIR, split_size)\n",
    "    # evaluate model\n",
    "    model, test_acc = evaluate_model(TRAINING_YES_DIR, TESTING_YES_DIR, TRAINING_NO_DIR, TESTING_NO_DIR, i)\n",
    "    print(\"**********************************************************************************************\")\n",
    "    print('>%.3f' % test_acc[1])\n",
    "    print(\"##############################################################################################\")\n",
    "    cv_scores.append(test_acc[1])\n",
    "    model_history.append(model)\n",
    "    \n",
    "print('Estimated Accuracy %.3f (%.3f)' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}